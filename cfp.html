<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<!--
Design by Free CSS Templates
http://www.freecsstemplates.org
Released for free under a Creative Commons Attribution 2.5 License
-->
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <title>EMDL Workshop 2026 - Call for Papers</title>
    <meta name="keywords" content="" />
    <meta name="description" content="" />
    <link href="default.css" rel="stylesheet" type="text/css" />
  </head>
  <body>
    <div id="header">
      <a href="https://www.sigmobile.org/mobisys/2026/"
        ><img align="right" vertical-align="text-top" width="35%" style="margin: 00px 5px" src="images/mobisys26.png"
      /></a>
      <h1>
        <a href="index.html">7th International Workshop on<br />Embedded and Mobile Deep Learning</a>
      </h1>
      <h2>
        Workshop co-located with
        <a href="https://www.sigmobile.org/mobisys/2026/">ACM MobiSys 2026</a>
      </h2>
      <h3>25 June '26 - Cambridge, UK</h3>
    </div>
    <div id="content">
      <div id="colOne">
        <h3 class="title">Call for Papers</h3>
        <p align="justify">
          Since its inception in 2017, the EMDL workshop has tracked how breakthroughs in deep learning transformed the
          interpretation of sensor data for mobile systems like smartphones and wearable devices. In the early years,
          the community focused on making standard inference feasible, overcoming the severe demands that deep models
          exerted on local resources. By 2022, these methods had matured, successfully adapting CNN and RNN
          architectures to meet the stringent needs of mixed-reality and cyber-physical systems.
        </p>

        <h4>The Shift: From Discriminative to Generative</h4>
        <p align="justify">
          However, the landscape has shifted once again. We are witnessing a transition from Discriminative AI
          (classifying sensor data) to Generative AI (reasoning, explaining, and acting on context). While Generative AI
          (GenAI) brings unprecedented capabilities, it also presents a resource wall. Modern edge devices operate under
          constraints in memory bandwidth and energy availability that standard GenAI architectures—which are
          memory-bound and autoregressive—fundamentally exceed. Currently, the most advanced models reside almost
          exclusively on the cloud, challenging the autonomy of mobile platforms.
        </p>

        <p align="justify">
          In this context, the mobile computing community is in a unique position to begin the careful study of two core
          technical questions re-framed for the GenAI era. First, how should systems be architected to partition these
          massive workloads? We must move beyond simple offloading to explore dynamic collaboration where mobile devices
          handle context and lightweight generation while the cloud supports heavy lifting. Second, what is required to
          integrate GenAI into resource-constrained systems? This necessitates a re-examination of efficiency, spanning
          from the compression of Transformer architectures and diffusion models to the software/hardware optimization
          of mobile processors (CPUs, GPUs, NPUs) for memory-intensive generation rather than traditional convolution.
        </p>

        <h4>Scope and Goals</h4>
        <p align="justify">
          EMDL 2026 explores the intersection of Systems and Generative AI. Unlike traditional AIoT approaches that
          focus on lightweight classification, this workshop addresses the unique systems challenges of GenAI
          deployment. We focus on the full stack of efficient deployment: from algorithmic compression to
          hardware-software co-design for resource-efficient reasoning on wearables, robots, and mobile devices. We
          invite researchers to submit work that answers core technical questions for the GenAI era:
        </p>
        <ol>
          <li>
            <b>Architecture:</b> How should systems be architected to partition massive workloads between the cloud and
            the edge?
          </li>
          <li>
            <b>Efficiency:</b> What is required to integrate memory-bound GenAI into resource-constrained systems?
          </li>
          <li>
            <b>Edge-Native Design:</b> How do we define edge-native generative models designed explicitly for physical
            constraints?
          </li>
        </ol>

        <h4>Topics of Interest</h4>
        <p align="justify">
          We solicit submissions including full technical workshop papers, white position papers, and
          work-in-progress/demos. Topics include, but are not limited to:
        </p>

        <p><b>Systems & Runtime</b></p>
        <ul>
          <li><b>Runtime Systems:</b> Inference engines and runtime management specifically for GenAI.</li>
          <li>
            <b>Memory Optimization:</b> KV cache optimization and memory management for autoregressive generation.
          </li>
          <li>
            <b>Hardware Acceleration:</b> Heterogeneous computing (CPU/GPU/NPU) optimization and FPGA mapping for
            transformers and diffusion models.
          </li>
          <li>
            <b>Collaborative Intelligence:</b> Dynamic collaboration/offloading where mobile devices handle context
            while the cloud supports heavy lifting.
          </li>
          <li>
            <b>Cloud-level Intelligence:</b> Enabling cloud-level intelligence on mobile platforms via system
            architectures and techniques.
          </li>
        </ul>

        <p><b>Models & Algorithms</b></p>
        <ul>
          <li>
            <b>Efficient GenAI:</b> On-device Large Language Models (LLMs) via quantization, pruning, and distillation.
          </li>
          <li>
            <b>Generative Media:</b> Diffusion models for text-to-image and image-to-video generation on edge devices.
          </li>
          <li><b>Multimodal Systems:</b> Generative systems combining vision, language, and audio inputs.</li>
          <li>
            <b>Retrieval-Augmented Generation (RAG):</b> Mobile-centric RAG architectures for on-device context
            retrieval.
          </li>
        </ul>

        <p><b>Applications & The Physical World</b></p>
        <ul>
          <li><b>Agentic AI:</b> Reasoning and agentic systems operating on resource-constrained devices.</li>
          <li><b>Benchmarking:</b> Evaluation methods and benchmarking for mobile GenAI performance.</li>
          <li><b>Real-World Deployment:</b> Experiences and case studies of GenAI.</li>
        </ul>
      </div>
      <div id="colTwo">
        <ul>
          <h2><a href="index.html">Home</a></h2>
          <h2><a href="cfp.html">Call for Papers</a> <a href="cfp.pdf">[PDF]</a></h2>
          <h2><a href="committee.html">Committees</a></h2>
          <!-- <h2><a href="keynote.html">Keynote Talks</a></h2> -->
          <h2><a href="attendee.html">Attendee Information</a></h2>
          <!-- <h2><a href="program.html">Technical Program</a></h2> -->
          <h2><a href="history.html">Prior Workshops</a></h2>
          <h2><a href="submission.html">Submissions</a></h2>
          <!-- <h2><a href="camera_ready.html">Camera-Ready Instructions</a></h2> -->

          <br />
          <li>
            <h2>Keynote Speakers</h2>
            <table>
              <tr valign="top">
                <td><img height="80" src="" /></td>
                <td><a href="">TBD</a><br />TBD</td>
              </tr>
              <tr valign="top">
                <td><img height="80" src="" /></td>
                <td><a href="">TBD</a><br />TBD</td>
              </tr>
            </table>
          </li>

          <br />
          <h2>Important Dates</h2>
          <ul>
            <li>
              <i><strong>Paper Submission Deadline</strong></i
              >:<br />&nbsp;&nbsp;&nbsp;&nbsp;2026 April 9th - 11:59PM AoE
            </li>
            <!-- <font color="0000FF">&nbsp;April 9th&nbsp; - 11:59PM AOE (Final)</font></li> -->
            <li style="line-height: 5px"><br /></li>
            <li>
              <i><strong>Author Notification</strong></i
              >: <br />&nbsp;&nbsp;&nbsp;&nbsp;2026 April 23th - 11:59pm AoE
            </li>
            <li style="line-height: 5px"><br /></li>
            <li>
              <i><strong>Camera Ready Due</strong></i
              >:<br />&nbsp;&nbsp;&nbsp;&nbsp;2026 April 30th - 11:59pm AoE
            </li>
            <!-- <li style="line-height: 5px"><br></li>
				<li><i><strong>WiP and Demo Deadline</strong></i>:<BR>&nbsp;&nbsp;&nbsp;&nbsp;2026 April 30th - 11:59PM AoE</li><li style="line-height: 5px"><br></li> -->
            <li>
              <i><strong>Workshop Event</strong></i
              >:<br />&nbsp;&nbsp;&nbsp;&nbsp;2026 June 25th
            </li>
          </ul>
        </ul>
        <br />
        <img width="50%" style="display: block; margin-left: auto; margin-right: auto" src="images/acm-logo2.png" />
        <br />
        <img width="50%" style="display: block; margin-left: auto; margin-right: auto" src="images/sigmobile.gif" />
      </div>
      <div style="clear: both">&nbsp;</div>
    </div>
    <div id="footer">
      <p></p>
    </div>
  </body>
</html>
